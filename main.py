import os
import re
import uuid
import logging
import asyncio
import openai
import uvicorn

from fastapi import FastAPI, Request, Form, Query
from fastapi.responses import HTMLResponse, RedirectResponse
from starlette.middleware.sessions import SessionMiddleware
from dotenv import load_dotenv
import html

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
ASSISTANT_ID = os.environ.get("ASSISTANT_ID", "default_assistant_id")
VECTOR_STORE_ID = os.environ.get("VECTOR_STORE_ID", "")

if not OPENAI_API_KEY:
    logger.error("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
openai.api_key = OPENAI_API_KEY

# ì•„ì´ì½˜ ë° í˜ë¥´ì†Œë‚˜ ì„¤ì •
ai_icon = "ğŸª·"
user_icon = "ğŸ§‘ğŸ»â€ğŸ’»"
ai_persona = "ìŠ¤ë‹˜ AI ì±—ë´‡"

app = FastAPI()
app.add_middleware(SessionMiddleware, secret_key="your-secret-key")

conversation_store = {}

def remove_citation_markers(text: str) -> str:
    return re.sub(r'ã€\d+:\d+â€ sourceã€‘', '', text)

def create_thread():
    try:
        thread = openai.beta.threads.create()
        return thread.id
    except Exception as e:
        logger.error(f"Thread creation failed: {e}")
        return None

def init_conversation(session_id: str):
    thread_id = create_thread()
    initial_message = (
        "ëª¨ë“  ë‹µì€ ë‹¹ì‹  ì•ˆì— ìˆìŠµë‹ˆë‹¤. "
        "ì €ëŠ” ê·¸ ì—¬ì •ì„ í•¨ê»˜í•˜ëŠ” ìŠ¤ë‹˜ AIì…ë‹ˆë‹¤. ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”? ğŸ™ğŸ»"
    )
    conversation_store[session_id] = {
        "thread_id": thread_id,
        "messages": [{"role": "assistant", "content": initial_message}]
    }

def get_conversation(session_id: str):
    if session_id not in conversation_store:
        init_conversation(session_id)
    return conversation_store[session_id]

async def get_assistant_reply_thread(thread_id: str, prompt: str) -> str:
    try:
        await asyncio.to_thread(
            openai.beta.threads.messages.create,
            thread_id=thread_id,
            role="user",
            content=f"ì‚¬ìš©ìê°€ {ai_persona}ê³¼ ëŒ€í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤: {prompt}"
        )
        run_params = {"thread_id": thread_id, "assistant_id": ASSISTANT_ID}
        if VECTOR_STORE_ID:
            run_params["tools"] = [{"type": "file_search"}]
        run = await asyncio.to_thread(openai.beta.threads.runs.create, **run_params)
        
        while run.status not in ["completed", "failed"]:
            run = await asyncio.to_thread(
                openai.beta.threads.runs.retrieve,
                thread_id=thread_id,
                run_id=run.id
            )
            if run.status == "completed":
                messages = await asyncio.to_thread(
                    openai.beta.threads.messages.list,
                    thread_id=thread_id
                )
                return remove_citation_markers(messages.data[0].content[0].text.value)
            elif run.status == "failed":
                return "ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            await asyncio.sleep(0.5)
    except Exception as e:
        logger.error(f"Error in get_assistant_reply_thread: {e}")
        return "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

def convert_newlines_to_br(text: str) -> str:
    escaped = html.escape(text)
    return escaped.replace('\n', '<br>')

def render_chat_interface(conversation) -> str:
    """
    - static í´ë” ì—†ì´ ì™¸ë¶€ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©
    - ë§í’
